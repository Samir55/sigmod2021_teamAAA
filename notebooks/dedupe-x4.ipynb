{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import logging\n",
    "import optparse\n",
    "import re\n",
    "import spacy\n",
    "import dedupe\n",
    "import pickle\n",
    "import copy\n",
    "import json\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('translations_lookup_all.json') as fin:\n",
    "    variants = json.load(fin)\n",
    "\n",
    "with open('langs_dict.json') as fin:\n",
    "    json.load(fin)\n",
    "    \n",
    "def get_type(record):\n",
    "    name = record['name'].lower()\n",
    "    \n",
    "    if pd.isna(record['size']):\n",
    "        if 'tv' in name:\n",
    "            return 'tv'\n",
    "        return 'mobile'\n",
    "    \n",
    "    \n",
    "    flash_keywords = ['usb', 'drive']\n",
    "    memory_stick_keywords = ['card', 'stick', 'sd', 'microsd', 'hc', 'class', 'speicherkarte'] # Add variants here\n",
    "    \n",
    "    is_flash = False\n",
    "    is_memory = False\n",
    "    \n",
    "    for w in flash_keywords:\n",
    "        if w in name:\n",
    "            is_flash = True\n",
    "            break\n",
    "            \n",
    "    for w in memory_stick_keywords:\n",
    "        if w in name:\n",
    "            is_memory = True\n",
    "            break\n",
    "    \n",
    "    if is_flash:\n",
    "        return 'flash'\n",
    "    \n",
    "    if is_memory:\n",
    "        return 'stick'\n",
    "    \n",
    "    return 'stick'\n",
    "\n",
    "def convert_numbers_to_strings(df, cols_to_convert, remove_point_zero=True):\n",
    "    \"\"\" Convert number types to strings in a dataframe.\n",
    "        This is convoluted as need to keep NoneTypes as NoneTypes for what comes next!\n",
    "        \n",
    "        Inputs: - df -> dataframe to convert number types\n",
    "                - cols_to_convert -> list of columns to convert\n",
    "                - remove_point_zero -> bool to say whether you want '.0' removed from number\n",
    "        \n",
    "        Ouputs: - dataframe with converted number types\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    for col in cols_to_convert:\n",
    "        if remove_point_zero:\n",
    "            new_df[col] = new_df[col].apply(lambda x: str(x).replace('.0','')\\\n",
    "                                            if not isinstance(x, type(None)) else x)\n",
    "        else:\n",
    "            new_df[col] = new_df[col].apply(lambda x: str(x)\\\n",
    "                                            if not isinstance(x, type(None)) else x)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def preprocess_products_dataset(x4_dev):\n",
    "    # Clean x4\n",
    "    # Alpha numeric\n",
    "    irrelevant_regex = re.compile(r'[^a-z0-9,.\\-\\s]')\n",
    "    multispace_regex = re.compile(r'\\s\\s+') # Why it doesn't work\n",
    "    x4_dev.replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "\n",
    "    for column in x4_dev.columns:\n",
    "        if column == 'instance_id':\n",
    "            continue\n",
    "        x4_dev[column] = x4_dev[column].str.lower().str.replace(irrelevant_regex, ' ').str.replace(multispace_regex, ' ')\n",
    "        \n",
    "    x4_dev['product_type'] = x4_dev.apply(get_type, axis=1)\n",
    "    x4_dev.drop('price', inplace=True, axis=1)\n",
    "    x4_dev['size'] = x4_dev['size'].str.lower().str.replace(' ', '')\n",
    "    x4_dev['size'] = x4_dev['size'].where(x4_dev['size'].notnull(), 0)\n",
    "    \n",
    "    # Remove unwanted words from the name\n",
    "    for i in range(len(x4_dev)):\n",
    "        record = x4_dev.iloc[i]\n",
    "\n",
    "        name = record['name']\n",
    "\n",
    "        # remove unnecessary characters\n",
    "        basic_punct = '-/\\*_,:;/()®™' \n",
    "        punct_to_space = str.maketrans(basic_punct, ' ' * len(basic_punct))  # map punctuation to space\n",
    "        name = name.translate(punct_to_space)\n",
    "\n",
    "        # remove brand\n",
    "        name = name.replace(record['brand'], '')\n",
    "\n",
    "        # remove size\n",
    "\n",
    "        if record.product_type in ['flash', 'stick']:\n",
    "            name = re.sub('\\d\\d\\d\\s?gb', '', name, 6)\n",
    "            name = re.sub('\\d\\d\\s?gb', '', name, 6)\n",
    "            name = re.sub('\\d\\s?gb', '', name, 6)\n",
    "\n",
    "        tokens = name.split(' ')\n",
    "        for wd, wdtl in variants.items():\n",
    "            while wd in tokens:\n",
    "                tokens.remove(wd)\n",
    "            for wdt in wdtl:\n",
    "                while wdt in tokens:\n",
    "                    tokens.remove(wdt) \n",
    "\n",
    "        unneeded_words = ['mmoire', 'speicherkarte', 'flashgeheugenkaart', 'flash', 'stick', 'speed', 'high']\n",
    "        for w in unneeded_words:\n",
    "            while w in tokens:\n",
    "                tokens.remove(w)\n",
    "        x4_dev.iloc[i]['name'] = ' '.join(tokens)\n",
    "\n",
    "    for column in x4_dev.columns:\n",
    "        if column == 'instance_id':\n",
    "            continue\n",
    "        x4_dev[column] = x4_dev[column].str.lower().str.replace(irrelevant_regex, ' ').str.replace(multispace_regex, ' ')\n",
    "        \n",
    "    return x4_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4 = pd.read_csv('../data/sigmod/X4.csv')\n",
    "x4_dev = convert_numbers_to_strings(x4, ['price']).copy(deep=True)\n",
    "x4_dev.set_index('instance_id', inplace=True)\n",
    "x4_dev = preprocess_products_dataset(x4_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dedupe = x4_dev[[\n",
    "    'name',\n",
    "    'brand',\n",
    "    'size',\n",
    "    'product_type']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>size</th>\n",
       "      <th>product_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instance_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>altosight.com//0</th>\n",
       "      <td>1400x 210mb s professional xqd memriakrtya</td>\n",
       "      <td>lexar</td>\n",
       "      <td>32gb</td>\n",
       "      <td>stick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>altosight.com//25</th>\n",
       "      <td>microsdxc uhs 1 u3 memriakrtya adapter srg1uxa</td>\n",
       "      <td>sony</td>\n",
       "      <td>128gb</td>\n",
       "      <td>stick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>altosight.com//66</th>\n",
       "      <td>dual drive type c usb 3.0 130 mb s</td>\n",
       "      <td>sandisk</td>\n",
       "      <td>16gb</td>\n",
       "      <td>flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>altosight.com//68</th>\n",
       "      <td>dual drive type c usb 3.0 150 mb s</td>\n",
       "      <td>sandisk</td>\n",
       "      <td>64gb</td>\n",
       "      <td>flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>altosight.com//94</th>\n",
       "      <td>xqd x1400 professional xqd kupon premium 50 n...</td>\n",
       "      <td>lexar</td>\n",
       "      <td>32gb</td>\n",
       "      <td>stick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                name    brand  \\\n",
       "instance_id                                                                     \n",
       "altosight.com//0          1400x 210mb s professional xqd memriakrtya    lexar   \n",
       "altosight.com//25    microsdxc uhs 1 u3 memriakrtya adapter srg1uxa      sony   \n",
       "altosight.com//66                 dual drive type c usb 3.0 130 mb s  sandisk   \n",
       "altosight.com//68                 dual drive type c usb 3.0 150 mb s  sandisk   \n",
       "altosight.com//94   xqd x1400 professional xqd kupon premium 50 n...    lexar   \n",
       "\n",
       "                    size product_type  \n",
       "instance_id                            \n",
       "altosight.com//0    32gb        stick  \n",
       "altosight.com//25  128gb        stick  \n",
       "altosight.com//66   16gb        flash  \n",
       "altosight.com//68   64gb        flash  \n",
       "altosight.com//94   32gb        stick  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dedupe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'altosight.com//0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dedupe_dict = to_dedupe.to_dict(orient = 'index')\n",
    "list(to_dedupe_dict.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs for this are here: \n",
    "fields = [{'field' : 'name', 'type' : 'String', 'has_missing' : False},\n",
    "          {'field' : 'brand', 'type': 'Categorical', 'categories' : list(x4_dev.brand.unique()), 'has_missing' : False}, \n",
    "          {'field' : 'size', 'type': 'Exact', 'has_missing' : False},\n",
    "          {'field' : 'product_type', 'type': 'Categorical', 'categories' : list(x4_dev.product_type.unique()),\n",
    "           'has_missing' : False}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a bug later on that requires num_cores to be 1, but we can make use of\n",
    "# multi-threaded processes in the meantime\n",
    "deduper = dedupe.Dedupe(fields, num_cores=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('../data/sigmod/Y4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainig_data = {'match': [], 'distinct': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding projects\\sigmod\\venv\\lib\\site-packages\\pandas\\core\\frame.py:1549: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  warnings.warn(\n",
      "d:\\coding projects\\sigmod\\venv\\lib\\site-packages\\pandas\\core\\frame.py:1549: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "match = y[y.label == 1].to_dict(orient='row')\n",
    "distinct = y[y.label == 0].to_dict(orient='row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in match:\n",
    "    trainig_data['match'].append( ( to_dedupe_dict[m['left_instance_id']], to_dedupe_dict[m['right_instance_id']] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4082"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainig_data['match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in distinct:\n",
    "    trainig_data['distinct'].append( ( to_dedupe_dict[d['left_instance_id']], to_dedupe_dict[d['right_instance_id']] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344113"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainig_data['distinct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.api:reading training from file\n",
      "INFO:dedupe.training:Final predicate set:\n",
      "INFO:dedupe.training:SimplePredicate: (wholeFieldPredicate, name)\n",
      "Exception ignored in: 'lbfgs._lowlevel.call_eval'\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\coding projects\\sigmod\\venv\\lib\\site-packages\\rlr\\lr.py\", line 73, in loss\n",
      "    g[:] = gradient(x0, X, y, case_weights, alpha)\n",
      "  File \"d:\\coding projects\\sigmod\\venv\\lib\\site-packages\\rlr\\lr.py\", line 86, in gradient\n",
      "    grad_c = z0.sum() \n",
      "  File \"d:\\coding projects\\sigmod\\venv\\lib\\site-packages\\numpy\\core\\_methods.py\", line 47, in _sum\n",
      "    return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: 'lbfgs._lowlevel.call_eval'\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\coding projects\\sigmod\\venv\\lib\\site-packages\\rlr\\lr.py\", line 73, in loss\n",
      "    g[:] = gradient(x0, X, y, case_weights, alpha)\n",
      "  File \"d:\\coding projects\\sigmod\\venv\\lib\\site-packages\\rlr\\lr.py\", line 82, in gradient\n",
      "    z = X.dot(w) + c\n",
      "KeyboardInterrupt: \n",
      "INFO:dedupe.training:Final predicate set:\n",
      "INFO:dedupe.training:SimplePredicate: (wholeFieldPredicate, brand)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32md:\\coding projects\\sigmod\\venv\\lib\\site-packages\\rlr\\lr.py\u001B[0m in \u001B[0;36mloss\u001B[1;34m(x0, g, X, y, case_weights, alpha)\u001B[0m\n\u001B[0;32m     71\u001B[0m     \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m.5\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0malpha\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m     \u001B[0mg\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcase_weights\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\coding projects\\sigmod\\venv\\lib\\site-packages\\rlr\\lr.py\u001B[0m in \u001B[0;36mgradient\u001B[1;34m(x0, X, y, case_weights, alpha)\u001B[0m\n\u001B[0;32m     84\u001B[0m     \u001B[0mz0\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mz\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mcase_weights\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m     \u001B[0mgrad_w\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mz0\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0malpha\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 86\u001B[1;33m     \u001B[0mgrad_c\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mz0\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     87\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad_w\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mgrad_c\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\coding projects\\sigmod\\venv\\lib\\site-packages\\numpy\\core\\_methods.py\u001B[0m in \u001B[0;36m_sum\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m     45\u001B[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001B[0;32m     46\u001B[0m          initial=_NoValue, where=True):\n\u001B[1;32m---> 47\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mumr_sum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwhere\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32md:\\coding projects\\sigmod\\venv\\lib\\site-packages\\rlr\\lr.py\u001B[0m in \u001B[0;36mloss\u001B[1;34m(x0, g, X, y, case_weights, alpha)\u001B[0m\n\u001B[0;32m     71\u001B[0m     \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m.5\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0malpha\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m     \u001B[0mg\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcase_weights\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\coding projects\\sigmod\\venv\\lib\\site-packages\\rlr\\lr.py\u001B[0m in \u001B[0;36mgradient\u001B[1;34m(x0, X, y, case_weights, alpha)\u001B[0m\n\u001B[0;32m     80\u001B[0m     \u001B[1;31m# gradient of the logistic loss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     81\u001B[0m     \u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx0\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx0\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 82\u001B[1;33m     \u001B[0mz\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mc\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     83\u001B[0m     \u001B[0mz\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mphi\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mz\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     84\u001B[0m     \u001B[0mz0\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mz\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mcase_weights\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "with open('y4_train.json', 'w') as fout:\n",
    "    json.dump(trainig_data, fout)\n",
    "    \n",
    "training_file = 'y4_train.json'\n",
    "with open(training_file) as tf:\n",
    "    deduper.prepare_training(to_dedupe_dict, training_file=tf, sample_size=1500, blocked_proportion=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('starting active labeling...')\n",
    "# dedupe.console_label(deduper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('y_4_augmented.json', 'w') as fout:\n",
    "#     json.dump(deduper.training_pairs, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rlr.crossvalidation:using cross validation to find optimum alpha...\n"
     ]
    }
   ],
   "source": [
    "deduper.train(recall=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "training_file = 'trained_model_x4.json'\n",
    "settings_file = 'trained_model_x4_settings.json'\n",
    "\n",
    "with open(training_file, 'w') as tf:\n",
    "    deduper.write_training(tf)\n",
    "with open(settings_file, 'wb') as sf:\n",
    "    deduper.write_settings(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clustered_dupes = deduper.partition(to_dedupe_dict, 0.5)\n",
    "print('# duplicate sets', len(clustered_dupes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for el in clustered_dupes:\n",
    "    for i in range(len(el[0])):\n",
    "        for j in range(i+1, len(el[0])):\n",
    "            res.append((el[0][i], el[0][j]))\n",
    "res_df =pd.DataFrame(res)          \n",
    "res_df.columns = ['left_instance_id', 'right_instance_id']\n",
    "res_df.to_csv(\"output_x4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "deduper.predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "deduper.partition(trainig_data, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "deduper.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}